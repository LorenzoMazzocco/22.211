{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tallies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates three different tally types to compute the absorption rate in a 1D slab problem.  The three approaches are: 1) analog tally: only when an actual absorption collision takes place, 2) collision tally: at each collision we compute the flux and multiply by the absorption macro xs, 3) pathlength tally: at each flight we compute the flux and multiply by the absorption macro xs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a monoenergetic problem with only scattering and absorption.  We are solving a 10cm slab and will tally absorption rates over a 1 cm mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_t = 1.5    #0.5\n",
    "Sigma_s = 1.2    #0.4\n",
    "Sigma_a = Sigma_t - Sigma_s\n",
    "A=12\n",
    "\n",
    "L = 10\n",
    "nps = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block sets the seed and initializes the tallies (mean) and the standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(a=2)\n",
    "analog_tally = np.zeros(L)\n",
    "collision_tally = np.zeros(L)\n",
    "track_tally = np.zeros(L)\n",
    "\n",
    "analog_tally_uq = np.zeros(L)\n",
    "collision_tally_uq = np.zeros(L)\n",
    "track_tally_uq = np.zeros(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block is the main loop.  In 1D, there is no need to track all three components of the direction vector, we only need the \"w\" component if we assume the slabs are along the \"z\" direction.  The is only one material in this problem, so the code tracks particles across the full length \"L\".  The tallies are done over a superimposed mesh that doesn't impact the tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nps):\n",
    "    s_track = np.zeros(L)   #initialize the history score\n",
    "    s_collision = np.zeros(L)\n",
    "    s_analog = np.zeros(L)\n",
    "    old_x = random.random()*L     #uniform source in space\n",
    "    old_mu = random.random()*2 -1   #uniform angle in the LAB\n",
    "    w=1.0   #initial particle weight\n",
    "    while True:    #while the particle is alive\n",
    "        s = -np.log(random.random())/Sigma_t    #sample distance traveled\n",
    "        new_x = old_x + s*old_mu    #calculate new position \n",
    "        #track tally\n",
    "        ind1 = int(old_x)        #mesh index of starting location\n",
    "        ind2 = int(new_x)        #mesh index of new location\n",
    "        ind2 = min(10,ind2)      #check the limits of the new location\n",
    "        ind2 = max(0,ind2)\n",
    "        if ind1 == ind2:         #if particle stays in same mesh\n",
    "            s_track[ind1] = s_track[ind1] + w*s*Sigma_a     #add pathlength contribution to pathlength history score\n",
    "        else:         \n",
    "            if old_mu < 0:       #if the particle is moving left\n",
    "                delta_x = old_x - float(ind1)\n",
    "                s_track[ind1] = s_track[ind1] + abs(w*delta_x/old_mu)*Sigma_a   #contribution to the initial cell\n",
    "                ind1 = ind1 - 1\n",
    "                while (ind1 != ind2):     #contribution to all cells between starting and end point\n",
    "                    s_track[ind1] = s_track[ind1] + abs(w*1.0/old_mu)*Sigma_a\n",
    "                    ind1 = ind1 - 1\n",
    "                delta_x = float(ind1+1) - new_x\n",
    "                if (new_x > 0.0 and new_x < 10.0):   #contribution to end cell\n",
    "                    s_track[ind1] = s_track[ind1] + abs(w*delta_x/old_mu)*Sigma_a\n",
    "            else:               #if particle is moving right\n",
    "                delta_x = float(ind1+1) - old_x\n",
    "                s_track[ind1] = s_track[ind1] + abs(w*delta_x/old_mu)*Sigma_a #contribution to the initial cell\n",
    "                ind1 = ind1 + 1\n",
    "                while (ind1 != ind2):    #contribution to all cells between starting and end point\n",
    "                    s_track[ind1] = s_track[ind1] + abs(w*1.0/old_mu)*Sigma_a\n",
    "                    ind1 = ind1 + 1\n",
    "                delta_x = new_x - float(ind1)\n",
    "                if (new_x > 0.0 and new_x < 10.0):   #contribution to end cell\n",
    "                    s_track[ind1] = s_track[ind1] + abs(w*delta_x/old_mu)*Sigma_a   \n",
    "        if new_x < 0:  #particle leaked on the left\n",
    "            #print('Leak to the left',i, new_x)\n",
    "            break\n",
    "        elif new_x > L:  #particle leaked on the right\n",
    "            #print('Leak to the right',i, new_x)\n",
    "            break\n",
    "        else:\n",
    "            ind = int(new_x)   #particle collided in cell ind\n",
    "            s_collision[ind] = s_collision[ind] + w*Sigma_a/Sigma_t    #contribution to the collision estimator\n",
    "            if random.random() < Sigma_s/Sigma_t:     #collision is scattering\n",
    "                # Isotropic in CM\n",
    "                cm_mu = random.random()*2-1           #isotropic scattering in COM\n",
    "                # Convert to LAB\n",
    "                lab_mu = (1+A*cm_mu)/np.sqrt(A**2+2*A*cm_mu+1)   #convert to LAB\n",
    "                lab_phi = random.random()*2*3.1416               #sample uniform azimuthal angle\n",
    "                new_mu = lab_mu*old_mu - np.sqrt(1-lab_mu**2)*np.sqrt(1-old_mu**2)*np.cos(lab_phi)   #rotate the vector\n",
    "                old_mu = new_mu              \n",
    "                old_x = new_x\n",
    "            else:     #collision is absorption\n",
    "                #print('Absorption Collision',i, new_x)\n",
    "                ind = int(new_x)\n",
    "                s_analog[ind] = s_analog[ind] + w    #contribution to the analog estimator\n",
    "                break\n",
    "    track_tally = track_tally + s_track                #once the history is the particle is over (outside the while loop)\n",
    "    collision_tally = collision_tally + s_collision    #we add the history contribution to each tally\n",
    "    analog_tally = analog_tally + s_analog\n",
    "    track_tally_uq = track_tally_uq + s_track**2       #we also add the square of the history contribution that we will need\n",
    "    collision_tally_uq = collision_tally_uq + s_collision**2    #to compute the variance\n",
    "    analog_tally_uq = analog_tally_uq + s_analog**2\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements the track length over a superimposed mesh tally which makes it much more complicated.  We could have instead separates the slab into 10 cells and stopped particle at each boundary which would be have the tallying easier but with the tradeoff of searching for intersections and re-sampling distance travelled.\n",
    "\n",
    "The other thing we can notice is how simple the collision and analog tallies are compared to the pathlength tallies.  The collision and absorption events are clearly defined while pathlenght requires computing the exact distance travelled at each flight.  This can also be seen when printing the tally accumulators. Analog and collision are integers in this case (since weight is always 1), while the pathlength are reals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([462., 625., 717., 802., 773., 804., 789., 739., 640., 468.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analog_tally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([466.2, 626.4, 744.2, 776.2, 796. , 802.8, 747.2, 719.6, 624.2,\n",
       "       469.4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collision_tally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([495.07754614, 628.97042249, 747.80925357, 774.51663612,\n",
       "       801.77871323, 803.42181889, 771.26866466, 716.31579091,\n",
       "       622.45815684, 453.66345229])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_tally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([462., 625., 717., 802., 773., 804., 789., 739., 640., 468.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analog_tally_uq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the accumulators (history and history squared), we can now compute the mean and variance/std deviation.  The blocks below compute the sample mean and the sample standard deviation for all three tally types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_tally = analog_tally/nps\n",
    "analog_tally_uq = np.sqrt((analog_tally_uq/nps - analog_tally**2)/(nps-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "collision_tally = collision_tally/nps\n",
    "collision_tally_uq = np.sqrt((collision_tally_uq/nps - collision_tally**2)/(nps-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_tally = track_tally/nps\n",
    "track_tally_uq = np.sqrt((track_tally_uq/nps - track_tally**2)/(nps-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The means from all three tallies are equivalent, but the analog estimator has a larger uncertainty. If you lower the absorption xs of this problem, this will increase the difference between analog and collision/pathlength.  \n",
    "\n",
    "The collision and pathlength estimators behave similarly for this case, but if you reduce the material density (lowering the macro xs), the pathlength estimator will performed better.\n",
    "\n",
    "Most Monte Carlo codes will default to pathlength estimators (OpenMC, MCNP), but some tally types do not work with pathlenght and will thus use a collision or analog estimator.  This usually happens when post-collision information is needed (energy out filters and angle out filters).\n",
    "\n",
    "SERPENT relies exclusively on collision estimators since their tracking is based on delta-tracking which would complicate the use of pathlength estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0462 0.0625 0.0717 0.0802 0.0773 0.0804 0.0789 0.0739 0.064  0.0468]\n",
      "[0.00209928 0.00242074 0.00258003 0.00271616 0.0026708  0.00271925\n",
      " 0.00269596 0.00261621 0.00244765 0.00211221]\n",
      "[0.04543907 0.03873177 0.03598374 0.03386735 0.03455113 0.03382152\n",
      " 0.03416934 0.03540205 0.03824456 0.04513265]\n"
     ]
    }
   ],
   "source": [
    "print(analog_tally)\n",
    "print(analog_tally_uq)\n",
    "print(analog_tally_uq/analog_tally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04662 0.06264 0.07442 0.07762 0.0796  0.08028 0.07472 0.07196 0.06242\n",
      " 0.04694]\n",
      "[0.00142269 0.00164411 0.00187374 0.00185166 0.00191027 0.00192164\n",
      " 0.00181274 0.00177293 0.00167996 0.00139351]\n",
      "[0.03051683 0.02624695 0.02517797 0.02385549 0.02399842 0.02393666\n",
      " 0.02426042 0.02463775 0.02691377 0.02968695]\n"
     ]
    }
   ],
   "source": [
    "print(collision_tally)\n",
    "print(collision_tally_uq)\n",
    "print(collision_tally_uq/collision_tally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04950775 0.06289704 0.07478093 0.07745166 0.08017787 0.08034218\n",
      " 0.07712687 0.07163158 0.06224582 0.04536635]\n",
      "[0.00147287 0.00142174 0.00160291 0.00161175 0.00166561 0.00168125\n",
      " 0.00161998 0.0015521  0.00141987 0.00112711]\n",
      "[0.02975023 0.02260418 0.02143478 0.02080977 0.02077388 0.02092616\n",
      " 0.02100408 0.02166777 0.02281064 0.0248447 ]\n"
     ]
    }
   ],
   "source": [
    "print(track_tally)\n",
    "print(track_tally_uq)\n",
    "print(track_tally_uq/track_tally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
